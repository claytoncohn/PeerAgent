from pinecone import Pinecone
import openai
import os
from dotenv import load_dotenv
load_dotenv()

"""
Load environment variables, process knowledge base data, generate embeddings, and upsert vectors into a Pinecone index.

This script reads in a knowledge base (KB) file, generates embeddings for its content using the OpenAI API, and inserts the embeddings into a Pinecone vector index.

Modules:
    pinecone (Pinecone): Used to interact with Pinecone for creating and managing vector indexes.
    openai: Provides access to the OpenAI API for generating embeddings.
    os: Provides access to environment variables.
    dotenv (load_dotenv): Loads environment variables from a `.env` file.

Attributes:
    PINECONE_API_KEY (str): The API key used to authenticate with Pinecone.
    pc (Pinecone): An instance of the Pinecone client.
    KB_PATH (str): The file path to the knowledge base document.
    data_string (str): The raw content of the knowledge base.
    data_arr (list of str): Split content of the knowledge base, where each element represents a concept or text block.
    data_labels (list of str): A list of labels for each corresponding entry in `data_arr`.
    data (list of dict): A list of dictionaries where each dictionary contains an ID and corresponding text from the knowledge base.
    embeddings (list of list of float): A list of embeddings generated by the OpenAI API.
    INDEX_NAME (str): The name of the Pinecone index used to store the vectors.
    PINECONE_NAMESPACE (str): The namespace for the Pinecone index.

Functions:
    embed(docs: list[str]) -> list[list[float]]:
        Generate embeddings for a list of documents using OpenAI's embedding model.

        Parameters:
            docs (list of str): A list of text documents to embed.

        Returns:
            list of list of float: A list of embeddings for the input documents.

Usage Example:
    The script reads the knowledge base file, generates embeddings for the entries, and upserts these vectors into a Pinecone index.
    Ensure that the `.env` file contains the correct environment variables (`PINECONE_API_KEY`, `KB_PATH`, `EMBEDDING_MODEL`, etc.).
"""

PINECONE_API_KEY = os.getenv(f"PINECONE_API_KEY")
pc = Pinecone(api_key=PINECONE_API_KEY)

KB_PATH = os.getenv("KB_PATH")
with open(KB_PATH) as f:
    data_string = "".join([line for line in f])

data_arr = data_string.split("\n\n")

data_labels = ["displacement","velocity","acceleration","time","final_velocity_eq","displacement_eq",\
               "velocity_squared_eq","updating_velocity_eq","updating_position_eq","variable","constant",\
                "init_variable","update_variable","loops","conditionals"]

assert len(data_arr)==len(data_labels)==15

data = [{"id":data_labels[i], "text":data_arr[i]} for i in range(len(data_labels))]

def embed(docs: list[str]) -> list[list[float]]:
    """
    Generate embeddings for a list of documents using the specified OpenAI embedding model.

    Parameters
    ----------
    docs : list of str
        A list of text documents to embed.

    Returns
    -------
    list of list of float
        A list of embeddings, where each embedding is a list of floats representing the input document.

    Notes
    -----
    The `EMBEDDING_MODEL` is retrieved from environment variables, which must specify the OpenAI model to be used for generating embeddings.
    """
    EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL")
    res = openai.embeddings.create(
        input=docs,
        model=EMBEDDING_MODEL
    )
    doc_embeds = [r.embedding for r in res.data]
    return doc_embeds

text_to_embed = [d["text"] for d in data]
embeddings = embed(docs=text_to_embed)

INDEX_NAME = os.getenv("PINECONE_INDEX")
index = pc.Index(INDEX_NAME)

vectors = []
for d, e in zip(data, embeddings):
    vectors.append({
        "id": d['id'],
        "values": e,
        "metadata": {'text': d['text']}
    })

PINECONE_NAMESPACE = os.getenv("PINECONE_NAMESPACE")
index.upsert(
    vectors=vectors,
    namespace=PINECONE_NAMESPACE
)

# print(index.describe_index_stats())